{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:31.378894Z",
     "start_time": "2018-04-27T10:34:29.903204Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "from functools import partial, lru_cache\n",
    "\n",
    "import pymorphy2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import fastText\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "Here we read the data, map label column to numbers and normalize texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:31.473463Z",
     "start_time": "2018-04-27T10:34:31.381336Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_COLUMNS = ['context_id', 'context_2', 'context_1', 'context_0', 'reply_id', 'reply']\n",
    "TRAIN_COLUMNS = TEST_COLUMNS + ['label', 'confidence']\n",
    "\n",
    "LABELS_MAPPING = {\n",
    "    'good': 2,\n",
    "    'neutral': 1,\n",
    "    'bad': 0, \n",
    "}\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "@lru_cache(maxsize=2**32)\n",
    "def normalize_word(word):\n",
    "    return morph.normal_forms(word)[0]\n",
    "\n",
    "def normalize_sent(sent):\n",
    "    return ' '.join(map(normalize_word, sent.split()))\n",
    "\n",
    "\n",
    "def do_basic_stuff(df):\n",
    "    if 'label' in df:\n",
    "        df['label'] = df.label.map(LABELS_MAPPING)\n",
    "        \n",
    "    df.fillna('', inplace=True)\n",
    "    df['context'] = df.context_2 + ' ' + df.context_1 + ' ' + df.context_0\n",
    "    \n",
    "    df['context_normalized'] = df.context.map(normalize_sent)\n",
    "    df['reply_normalized'] = df.reply.map(normalize_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:50.287996Z",
     "start_time": "2018-04-27T10:34:31.725821Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.tsv', sep='\\t', header=None, quoting=csv.QUOTE_NONE, names=TRAIN_COLUMNS)\n",
    "public = pd.read_csv('data/public.tsv', sep='\\t', header=None, quoting=csv.QUOTE_NONE, names=TEST_COLUMNS)\n",
    "final = pd.read_csv('data/final.tsv', sep='\\t', header=None, quoting=csv.QUOTE_NONE, names=TEST_COLUMNS)\n",
    "\n",
    "do_basic_stuff(train)\n",
    "do_basic_stuff(public)\n",
    "do_basic_stuff(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation split\n",
    "\n",
    "I fixed 3500 context_ids for validation (~25% of the training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:50.401006Z",
     "start_time": "2018-04-27T10:34:50.291745Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "validation_contexts = set(np.random.choice(np.unique(train.context_id), 3500, replace=False))\n",
    "validation_mask = train.context_id.isin(validation_contexts)\n",
    "\n",
    "validation = train[validation_mask].reset_index(drop=True)\n",
    "train = train[~validation_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making features\n",
    "\n",
    "Here is a feature making function. It takes a `func` and apllies it to train, validation and final datasets to generate all kinds of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:50.409591Z",
     "start_time": "2018-04-27T10:34:50.403638Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_features(func):\n",
    "    return func(train), func(validation), func(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:50.769872Z",
     "start_time": "2018-04-27T10:34:50.413005Z"
    }
   },
   "outputs": [],
   "source": [
    "# Raw texts\n",
    "contexts = pd.concat([\n",
    "    train.context,\n",
    "    validation.context,\n",
    "    public.context,\n",
    "    # I tried to use final set here instead of public, but it made things worse\n",
    "    # Probably because of the noise in the final dataset\n",
    "]).drop_duplicates().values\n",
    "\n",
    "counts = Counter(word for sent in contexts for word in set(sent.split()))\n",
    "IDF = {word: np.log(len(contexts) / count) for word, count in counts.items()}\n",
    "\n",
    "\n",
    "# Normalize texts\n",
    "\n",
    "contexts_normalized = pd.concat([\n",
    "    train.context_normalized,\n",
    "    validation.context_normalized,\n",
    "    public.context_normalized,\n",
    "]).drop_duplicates().values\n",
    "\n",
    "counts_normalized = Counter(word for sent in contexts_normalized for word in set(sent.split()))\n",
    "IDFn = {word: np.log(len(contexts) / count) for word, count in counts_normalized.items()}\n",
    "\n",
    "\n",
    "def simple_features(df):\n",
    "    \n",
    "    def idf_weight(sent, idf):\n",
    "        return sum(idf.get(word, 0) for word in sent)\n",
    "    \n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['reply_word_count'] = df.reply.str.split().map(len)\n",
    "    res['context_word_count'] = df.context.str.split().map(len)\n",
    "    res['context_0_word_count'] = df.context_0.str.split().map(len)\n",
    "    \n",
    "    res['reply_equals_to_context_0'] = df.reply == df.context_0\n",
    "    res['reply_is_in_context'] = df.apply(lambda x: x['reply'] in x['context'], axis=1)\n",
    "    res['reply_is_in_context_0'] = df.apply(lambda x: x['reply'] in x['context_0'], axis=1)\n",
    "\n",
    "    res['reply_idf'] = df.reply.str.split().map(partial(idf_weight, idf=IDF))\n",
    "    res['reply_idfn'] = df.reply.str.split().map(partial(idf_weight, idf=IDFn))\n",
    "    res['reply_idfnn'] = df.reply_normalized.str.split().map(partial(idf_weight, idf=IDFn))\n",
    "    res['context_idf'] = df.context.str.split().map(partial(idf_weight, idf=IDF))\n",
    "    res['context_idfn'] = df.context.str.split().map(partial(idf_weight, idf=IDFn))\n",
    "    res['context_idfnn'] = df.context_normalized.str.split().map(partial(idf_weight, idf=IDFn))\n",
    "    res['context_0_idf'] = df.context_0.str.split().map(partial(idf_weight, idf=IDF))\n",
    "    \n",
    "    def get_intersection(row):\n",
    "        return set(row['reply'].split()) & set(row['context_0'].split())\n",
    "    \n",
    "    intersection = train.apply(get_intersection, axis=1)\n",
    "    res['context_0_intersection_word_count'] = intersection.map(len)\n",
    "    res['context_0_intersection_idf'] = intersection.map(partial(idf_weight, idf=IDF))\n",
    "    res['context_0_intersection_idfn'] = intersection.map(partial(idf_weight, idf=IDFn))\n",
    "    \n",
    "    intersection = train.apply(get_intersection, axis=1)\n",
    "    res['context_intersection_word_count'] = intersection.map(len)\n",
    "    res['context_intersection_idf'] = intersection.map(partial(idf_weight, idf=IDF))\n",
    "    \n",
    "    return res.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:35.354630Z",
     "start_time": "2018-04-27T10:34:50.772800Z"
    }
   },
   "outputs": [],
   "source": [
    "train_simple_features, validation_simple_features, final_simple_features = \\\n",
    "    make_features(simple_features)\n",
    "    \n",
    "train_simple_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:35.362045Z",
     "start_time": "2018-04-27T10:35:35.357205Z"
    }
   },
   "outputs": [],
   "source": [
    "train_simple_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special tfidf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:22:58.636307Z",
     "start_time": "2018-04-24T13:22:46.139316Z"
    }
   },
   "outputs": [],
   "source": [
    "vect_1 = TfidfVectorizer(ngram_range=(1, 3), analyzer='char', max_features=2000)\n",
    "vect_1.fit(train.reply)\n",
    "\n",
    "vect_2 = TfidfVectorizer(ngram_range=(1, 2), analyzer='word', max_features=2000)\n",
    "vect_2.fit(train.context)\n",
    "\n",
    "vect_3 = TfidfVectorizer(ngram_range=(1, 2), analyzer='char', use_idf=False)\n",
    "vect_3.fit(train.context)\n",
    "\n",
    "def vectorizer_features(df):\n",
    "    features = []\n",
    "    columns = [\n",
    "        'vect_1_reply_context_mul',\n",
    "        'vect_1_reply_context_0_mul',\n",
    "        'vect_1_reply_context_1_mul',\n",
    "        \n",
    "        'vect_2_reply_context_mul',\n",
    "        'vect_2_reply_context_0_mul',\n",
    "        'vect_2_reply_context_1_mul',\n",
    "        \n",
    "        'vect_3_reply_context_mul',\n",
    "        'vect_3_reply_context_0_mul',\n",
    "        'vect_3_reply_context_1_mul',\n",
    "    ]\n",
    "    for vect in [vect_1, vect_2, vect_3]:\n",
    "        repl = vect.transform(df.reply)\n",
    "        cont = vect.transform(df.context)\n",
    "        cont_0 = vect.transform(df.context_0)\n",
    "        cont_1 = vect.transform(df.context_0)\n",
    "        \n",
    "        features.extend([\n",
    "            np.ravel(repl.multiply(cont).sum(1)),\n",
    "            np.ravel(repl.multiply(cont_0).sum(1)),\n",
    "            np.ravel(repl.multiply(cont_1).sum(1)),\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    # I forgot float32 type conversion here :(\n",
    "    # But I don't want any changes that may break anything now\n",
    "    return pd.DataFrame(np.hstack([features]).T, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:24:52.492256Z",
     "start_time": "2018-04-24T13:22:58.638707Z"
    }
   },
   "outputs": [],
   "source": [
    "train_vectorizer_features, validation_vectorizer_features, final_vectorizer_features = \\\n",
    "    make_features(vectorizer_features)\n",
    "    \n",
    "train_vectorizer_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pymorphy2 tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:24:52.509745Z",
     "start_time": "2018-04-24T13:24:52.494815Z"
    }
   },
   "outputs": [],
   "source": [
    "# I just randomly fixed the order by mistake and cant't reorder them now,\n",
    "# beacuse it will lead to slightly different training results\n",
    "KNOWN_GRAMMEMES = [\n",
    "    'ADVB', 'Subx', 'Dmns', 'Prnt', 'INTJ', 'Refl', 'nomn', 'Name', 'ablt', 'Anum',\n",
    "    'V-be', 'Dist', 'real', 'ADJF', 'Adjx', 'perf', 'MOod', 'ADJS', 'Abbr', 'Trad', \n",
    "    'masc', 'inan', 'voct', 'NUMR', 'CONJ', 'Vpre', 'tran', 'COMP', 'Prdx', 'Ques', \n",
    "    'Sgtm', 'Poss', 'Coun', 'intg', 'PREP', '3per', 'impf', '2per', 'VERB', 'futr', \n",
    "    'Supr', 'Fixd', 'plur', 'Mult', 'Infr', 'Fimp', 'TRns', 'actv', 'CAse', 'INvl', \n",
    "    'NUMB', 'Inmx', 'GRND', 'VOic', 'ANim', 'gent', 'V-ey', 'Orgn', 'Impe', 'Impx', \n",
    "    'Coll', 'ROMN', 'loc2', 'V-oy', 'V-bi', 'NOUN', 'gen2', 'Arch', 'Surn', 'loc1', \n",
    "    'V-ie', 'V-sh', 'Pltm', 'Erro', 'UNKN', 'Litr', 'Geox', 'intr', 'loct', 'GNdr', \n",
    "    'TEns', 'PNCT', '1per', 'Anph', 'acc2', 'Patr', 'ASpc', 'Ms-f', 'gen1', 'excl', \n",
    "    'Apro', 'V-ej', 'Slng', 'Cmp2', 'PErs', 'INFN', 'PRTF', 'datv', 'anim', 'impr', \n",
    "    'femn', 'Af-p', 'NPRO', 'incl', 'accs', 'sing', 'indc', 'Init', 'PRTS', 'PRED', \n",
    "    'pres', 'PRCL', 'NMbr', 'pssv', 'LATN', 'POST', 'past', 'V-en', 'Qual', 'neut',\n",
    "]\n",
    "\n",
    "@lru_cache(maxsize=2**32)\n",
    "def get_tags(word):\n",
    "    return Counter(morph.tag(word)[0].grammemes)\n",
    "\n",
    "\n",
    "def get_tags_dataframe(series):\n",
    "    df = pd.DataFrame(\n",
    "        list(series.map(lambda sent: sum(map(get_tags, sent.split()), Counter()))), \n",
    "        columns=KNOWN_GRAMMEMES\n",
    "    ).fillna(0)\n",
    "    return df.div(df.sum(1), axis='rows').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:25:40.253089Z",
     "start_time": "2018-04-24T13:24:52.512752Z"
    }
   },
   "outputs": [],
   "source": [
    "train_reply_grammems, validation_reply_grammems, final_reply_grammems = \\\n",
    "    make_features(lambda df: get_tags_dataframe(df.reply))\n",
    "    \n",
    "train_context_0_grammems, validation_context_0_grammems, final_context_0_grammems = \\\n",
    "    make_features(lambda df: get_tags_dataframe(df.context_0))\n",
    "    \n",
    "train_reply_grammems.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fasttext features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T13:35:40.361522Z",
     "start_time": "2018-04-24T13:25:40.255326Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fasttextWiki = KeyedVectors.load_word2vec_format('data/ext/wiki.ru.vec', binary=False)\n",
    "\n",
    "def get_sent_vector(sent):\n",
    "    res = np.zeros(300)\n",
    "    for word in sent.split():\n",
    "        if word in fasttextWiki:\n",
    "            res += fasttextWiki[word]  \n",
    "    return res\n",
    "\n",
    "\n",
    "def embed_sentences(df, column):\n",
    "    x = np.array([get_sent_vector(sent) for sent in df[column]])\n",
    "    return pd.DataFrame(\n",
    "        x / (1 + np.sqrt(np.square(x).sum(1, keepdims=True))),\n",
    "        index=df.index,\n",
    "        columns=['fasttext_wiki_%s_%d' % (column, i) for i in range(300)]\n",
    "    ).astype(np.float32)\n",
    "\n",
    "\n",
    "train_fasttext_wiki_context_0, validation_fasttext_wiki_context_0, final_fasttext_wiki_context_0 = \\\n",
    "    make_features(partial(embed_sentences, column='context_0'))\n",
    "    \n",
    "train_fasttext_wiki_reply, validation_fasttext_wiki_reply, final_fasttext_wiki_reply = \\\n",
    "    make_features(partial(embed_sentences, column='reply'))\n",
    "    \n",
    "train_fasttext_wiki_reply.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:08:12.504317Z",
     "start_time": "2018-04-24T14:07:15.826989Z"
    }
   },
   "outputs": [],
   "source": [
    "fasttextCC = fastText.load_model('data/ext/cc.ru.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:08:12.534170Z",
     "start_time": "2018-04-24T14:08:12.514673Z"
    }
   },
   "outputs": [],
   "source": [
    "def embed_fasttext_reply_cc(df):\n",
    "    return pd.DataFrame(\n",
    "        np.array(df.reply.map(fasttextCC.get_sentence_vector).tolist()),\n",
    "        index=df.index,\n",
    "        columns=['fasttext_cc_reply_%d' % i for i in range(300)],\n",
    "    ).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:08:22.173956Z",
     "start_time": "2018-04-24T14:08:12.539887Z"
    }
   },
   "outputs": [],
   "source": [
    "train_fasttext_cc_reply, validation_fasttext_cc_reply, final_fasttext_cc_reply = \\\n",
    "    make_features(embed_fasttext_reply_cc)\n",
    "    \n",
    "train_fasttext_cc_reply.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:09:01.142840Z",
     "start_time": "2018-04-24T14:08:22.179013Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 3), analyzer='char', max_features=2000)\n",
    "tfidf.fit(train.reply)\n",
    "\n",
    "\n",
    "train_reply_tfidf = tfidf.transform(train.reply).astype(np.float32)\n",
    "train_context_0_tfidf = tfidf.transform(train.context_0).astype(np.float32)\n",
    "train_mul_tfidf = train_reply_tfidf.multiply(train_context_0_tfidf)\n",
    "train_mul_sum_tfidf = train_mul_tfidf.sum(1)\n",
    "\n",
    "validation_reply_tfidf = tfidf.transform(validation.reply).astype(np.float32)\n",
    "validation_context_0_tfidf = tfidf.transform(validation.context_0).astype(np.float32)\n",
    "validation_mul_tfidf = validation_reply_tfidf.multiply(validation_context_0_tfidf)\n",
    "validation_mul_sum_tfidf = validation_mul_tfidf.sum(1)\n",
    "\n",
    "final_reply_tfidf = tfidf.transform(final.reply).astype(np.float32)\n",
    "final_context_0_tfidf = tfidf.transform(final.context_0).astype(np.float32)\n",
    "final_mul_tfidf = final_reply_tfidf.multiply(final_context_0_tfidf)\n",
    "final_mul_sum_tfidf = final_mul_tfidf.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD decoposition of tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:09:08.657117Z",
     "start_time": "2018-04-24T14:09:01.147484Z"
    }
   },
   "outputs": [],
   "source": [
    "svd_1 = TruncatedSVD(n_components=10, random_state=0, n_iter=15)\n",
    "svd_2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), analyzer='word', max_features=2000)),\n",
    "    ('svd', TruncatedSVD(n_components=10, random_state=0, n_iter=15)),\n",
    "])\n",
    "\n",
    "svd_1.fit(train_reply_tfidf)\n",
    "svd_2.fit(train.reply)\n",
    "\n",
    "\n",
    "train_svd_1 = svd_1.transform(train_reply_tfidf)\n",
    "train_svd_2 = svd_2.transform(train.reply)\n",
    "\n",
    "validation_svd_1 = svd_1.transform(validation_reply_tfidf)\n",
    "validation_svd_2 = svd_2.transform(validation.reply)\n",
    "\n",
    "final_svd_1 = svd_1.transform(final_reply_tfidf)\n",
    "final_svd_2 = svd_2.transform(final.reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:09:33.865292Z",
     "start_time": "2018-04-24T14:09:08.662344Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtrain = sparse.hstack([\n",
    "    train_reply_tfidf,\n",
    "    train_context_0_tfidf,\n",
    "    train_svd_1,\n",
    "    train_svd_2,\n",
    "    train_reply_grammems, \n",
    "    train_context_0_grammems,\n",
    "    train_fasttext_wiki_reply,\n",
    "    train_fasttext_wiki_context_0,\n",
    "    train_fasttext_cc_reply,\n",
    "    train_simple_features,\n",
    "    train_mul_sum_tfidf,\n",
    "    train_vectorizer_features,\n",
    "    train_mul_tfidf,\n",
    "]).tocsr()\n",
    "\n",
    "Xvalidation = sparse.hstack([\n",
    "    validation_reply_tfidf,\n",
    "    validation_context_0_tfidf,\n",
    "    validation_svd_1,\n",
    "    validation_svd_2,\n",
    "    validation_reply_grammems, \n",
    "    validation_context_0_grammems,\n",
    "    validation_fasttext_wiki_reply,\n",
    "    validation_fasttext_wiki_context_0,\n",
    "    validation_fasttext_cc_reply,\n",
    "    validation_simple_features,\n",
    "    validation_mul_sum_tfidf,\n",
    "    validation_vectorizer_features,\n",
    "    validation_mul_tfidf,\n",
    "]).tocsr()\n",
    "\n",
    "Xfinal = sparse.hstack([\n",
    "    final_reply_tfidf,\n",
    "    final_context_0_tfidf,\n",
    "    final_svd_1,\n",
    "    final_svd_2,\n",
    "    final_reply_grammems, \n",
    "    final_context_0_grammems,\n",
    "    final_fasttext_wiki_reply,\n",
    "    final_fasttext_wiki_context_0,\n",
    "    final_fasttext_cc_reply,\n",
    "    final_simple_features,\n",
    "    final_mul_sum_tfidf,\n",
    "    final_vectorizer_features,\n",
    "    final_mul_tfidf,\n",
    "]).tocsr()\n",
    "\n",
    "ytrain = train.label.values\n",
    "yvalidation = validation.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T09:26:02.995424Z",
     "start_time": "2018-04-24T09:26:00.392596Z"
    }
   },
   "source": [
    "# lighgbm models\n",
    "\n",
    "We will use two estimators: one to estimate the probability of a \"good\" class, and the other one for a \"bad\" class. I'm to lazy to really optimize hyperparameters, so it's pretty much default, except for `colsample_bytree` which is low, because we have lots of features (`colsample_bytree=0.5` overtfits a lot). Since features are exactly the same I used different random state to at least select features in deffirent order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:09:33.910158Z",
     "start_time": "2018-04-24T14:09:33.873271Z"
    }
   },
   "outputs": [],
   "source": [
    "bst_good = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.025, colsample_bytree=0.3, random_state=0)\n",
    "bst_bad = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.025, colsample_bytree=0.3, random_state=42)\n",
    "\n",
    "print('Training models on %d features' % Xtrain.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training final models on complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:33:01.342135Z",
     "start_time": "2018-04-24T14:33:00.437114Z"
    }
   },
   "outputs": [],
   "source": [
    "Xall = sparse.vstack([Xtrain, Xvalidation])\n",
    "yall = np.concatenate([ytrain, yvalidation])\n",
    "wall = np.concatenate([train.confidence, validation.confidence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T15:00:23.981537Z",
     "start_time": "2018-04-24T14:33:01.344467Z"
    }
   },
   "outputs": [],
   "source": [
    "bst_good.fit(Xall, yall == 2, sample_weight=wall)\n",
    "bst_bad.fit(Xall, yall == 0, sample_weight=wall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T15:00:41.630632Z",
     "start_time": "2018-04-24T15:00:23.986110Z"
    }
   },
   "outputs": [],
   "source": [
    "p_good = bst_good.predict_proba(Xfinal)[:, 1]\n",
    "p_bad = bst_bad.predict_proba(Xfinal)[:, 1]\n",
    "final['lgb_score'] = p_good - p_bad\n",
    "\n",
    "final[['context_id', 'reply_id', 'lgb_score']].to_csv('lgb_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T15:00:50.919274Z",
     "start_time": "2018-04-24T15:00:41.633017Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = final.groupby('context_id').apply(\n",
    "    lambda x: x.sort_values('lgb_score', ascending=False).reply_id\n",
    ").reset_index(level=0)\n",
    "\n",
    "sub.to_csv('lgb-final-sub.tsv', index=False, header=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T15:00:50.944165Z",
     "start_time": "2018-04-24T15:00:50.921650Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = ['reply_' + s for s in list(sorted(tfidf.vocabulary_))] + \\\n",
    "                ['context_0_' + s for s in list(sorted(tfidf.vocabulary_))] + \\\n",
    "                ['svd_1_%d' % d for d in range(10)] + \\\n",
    "                ['svd_2_%d' % d for d in range(10)] + \\\n",
    "                list(validation_reply_grammems.columns) + \\\n",
    "                list(validation_context_0_grammems.columns) + \\\n",
    "                list(validation_fasttext_wiki_reply.columns) + \\\n",
    "                list(validation_fasttext_wiki_context_0.columns) + \\\n",
    "                list(validation_fasttext_cc_reply.columns) + \\\n",
    "                list(validation_simple_features.columns) + \\\n",
    "                ['tfidf_dist'] + \\\n",
    "                list(validation_vectorizer_features.columns) + \\\n",
    "                ['multiply_' + s for s in list(sorted(tfidf.vocabulary_))]\n",
    "                \n",
    "imp = pd.DataFrame({\n",
    "    'imp_bad': bst_bad.feature_importances_,\n",
    "    'imp_good': bst_good.feature_importances_,\n",
    "}, index=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T15:00:50.967309Z",
     "start_time": "2018-04-24T15:00:50.947227Z"
    }
   },
   "outputs": [],
   "source": [
    "imp.sort_values('imp_bad', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T15:00:50.982749Z",
     "start_time": "2018-04-24T15:00:50.970700Z"
    }
   },
   "outputs": [],
   "source": [
    "imp.sort_values('imp_good', ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
